{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Siamese_net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "myenv1",
      "language": "python",
      "name": "gputest"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronaldocr9803/Hand_sig/blob/master/Siamese_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhWdugyEq25I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "import time\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from tensorflow.python.keras.models import Model\n",
        "import seaborn as sns\n",
        "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.python.keras.optimizers import *\n",
        "# from tensorflow.keras.engine.topology import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.regularizers import l2\n",
        "\n",
        "from tensorflow.python.keras.layers.pooling import MaxPooling2D\n",
        "from tensorflow.python.keras.layers.merge import Concatenate\n",
        "from tensorflow.python.keras.layers.core import Lambda, Flatten, Dense\n",
        "from tensorflow.python.keras.initializers import glorot_uniform\n",
        "\n",
        "# from tensorflow.keras.engine.topology import Layer\n",
        "# from tensorflow.keras.layers import Layer, InputSpec, Dropout, Flatten\n",
        "from tensorflow.python.keras.layers import *\n",
        "\n",
        "from tensorflow.python.keras.regularizers import l2\n",
        "from tensorflow.python.keras import backend as K\n",
        "# from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.python.keras.callbacks import *\n",
        "\n",
        "K.set_image_data_format('channels_last')\n",
        "import cv2\n",
        "import os\n",
        "# from skimage import io\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "# from fr_utils import *\n",
        "# from inception_blocks_v2 import *\n",
        "import numpy.random as rng\n",
        "from sklearn.utils import shuffle\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "from tensorflow.keras.optimizers import *\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uzowIDTg0tcJ",
        "tags": [],
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "import time\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "import seaborn as sns\n",
        "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.optimizers import *\n",
        "# from tensorflow.keras.engine.topology import Layer\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.regularizers import l2\n",
        "K.set_image_data_format('channels_last')\n",
        "import cv2\n",
        "import os\n",
        "# from skimage import io\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "# from fr_utils import *\n",
        "# from inception_blocks_v2 import *\n",
        "import numpy.random as rng\n",
        "from sklearn.utils import shuffle\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nCTmKrWSfhwt",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2 \n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.python.keras.layers.pooling import MaxPooling2D\n",
        "from tensorflow.python.keras.layers.merge import Concatenate\n",
        "from tensorflow.python.keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "# from tensorflow.keras.engine.topology import Layer\n",
        "# from tensorflow.keras.layers import Layer, InputSpec, Dropout, Flatten\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "from tensorflow.python.keras.regularizers import l2\n",
        "from tensorflow.python.keras import backend as K\n",
        "# from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.python.keras.callbacks import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hnjJ-_MQflID",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8aa84bb-1f8f-4a57-9987-211374b22637"
      },
      "source": [
        "print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E:\\TT20193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUUzm-Wsq25b",
        "colab_type": "code",
        "colab": {},
        "outputId": "2eda398a-d7ee-40be-b9f2-ca0441e0d018"
      },
      "source": [
        "tf.test.is_built_with_cuda()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "qqSG5noIq25f",
        "colab_type": "code",
        "colab": {},
        "outputId": "ab3334f9-2a20-4073-e3bb-4fa2d02139f7"
      },
      "source": [
        "tf.config.list_physical_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjsZ8x8kq25j",
        "colab_type": "code",
        "colab": {},
        "outputId": "7f457615-aa52-430f-9b16-d4ee3bc82bd8"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "def get_available_gpus():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
        "get_available_gpus()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "NsmSiXckq25n",
        "colab_type": "code",
        "colab": {},
        "outputId": "d3d886c1-d3d4-4c94-a7e6-a234cbc7dd6e"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_IyTalfsfnQU",
        "colab": {}
      },
      "source": [
        "cd /content/drive/My Drive/Colab Notebooks/TT20193"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xq8ZEOIQb2ES",
        "colab": {}
      },
      "source": [
        "lst_val_folder = ['362', '363', '364', '365', '366', '367', '368', '369', '37', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '38', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '39', '390', '391', '392', '393', '394', '395', '396', '397', '398', '399', '4', '40', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '41', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '42', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '43', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '44', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '45', '450', '451', '452', '453', '454', '455', '456', '457', '458', '459', '46', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '47', '470', '471', '472', '473', '474', '475', '476', '477', '478', '479', '48', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '49', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '5', '50', '500', '501', '502', '503', '504', '506', '507', '508', '509', '51', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '52', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '53', '530', '531', '532', '533', '534', '535', '536', '537', '538', '539', '54', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '55', '550', '551', '552']\n",
        "lst_test_folder = ['630', '631', '632', '633', '634', '635', '636', '637', '638', '639', '64', '640', '641', '642', '643', '644', '645', '646', '647', '648', '649', '65', '650', '651', '652', '653', '654', '655', '656', '657', '658', '659', '66', '660', '661', '662', '663', '664', '665', '666', '667', '668', '669', '67', '670', '671', '672', '673', '674', '675', '676', '677', '678', '679', '68', '680', '681', '682', '683', '684', '685', '686', '687', '688', '689', '69', '690', '691', '692', '693', '694', '695', '696', '697', '698', '699', '7', '70', '700', '701', '702', '703', '704', '705', '706', '707', '708', '709', '71', '710', '711', '712', '713', '714', '715', '716', '717', '718', '719', '72', '720', '721', '722', '723', '724', '725', '726', '727', '728', '729', '73', '730', '731', '732', '733', '734', '735', '736', '737', '738', '739', '74', '740', '741', '742', '743', '744', '745', '746', '747', '748', '749', '75', '750', '751', '752', '753', '754', '755', '756', '757', '758', '759', '76', '760', '761', '762', '763', '764', '765', '766', '767', '768', '769', '77', '770', '771', '772', '773', '774', '775', '776', '777', '778', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']\n",
        "lst_train_folder = [folder_img for folder_img in os.listdir(\"Generated_data\") if not folder_img.startswith('.') and folder_img not in lst_val_folder and folder_img not in lst_test_folder]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W1sEKSa-t3x1",
        "colab": {}
      },
      "source": [
        "def euclidean_distance(vects):\n",
        "    '''Compute Euclidean Distance between two vectors'''\n",
        "    x, y = vects\n",
        "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n",
        "\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    '''Contrastive loss from Hadsell-et-al.'06\n",
        "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    '''\n",
        "    margin = 1\n",
        "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "roV5YtXuquge",
        "colab": {}
      },
      "source": [
        "def create_base_network_signet(input_shape):\n",
        "    '''Base Siamese Network'''\n",
        "    \n",
        "    seq = Sequential()\n",
        "    seq.add(Conv2D(96, kernel_size=(11, 11), activation='relu', name='conv1_1', strides=4, input_shape= input_shape))\n",
        "    # seq.add(BatchNormalization(epsilon=1e-06, mode=0, axis=1, momentum=0.9))\n",
        "    seq.add(MaxPooling2D((3,3), strides=(2, 2)))    \n",
        "    seq.add(ZeroPadding2D((2, 2)))\n",
        "\n",
        "    seq.add(Conv2D(256, kernel_size=(5, 5), activation='relu', name='conv2_1', strides=1))\n",
        "    # seq.add(BatchNormalization(epsilon=1e-06, mode=0, axis=1, momentum=0.9))\n",
        "    seq.add(MaxPooling2D((3,3), strides=(2, 2)))\n",
        "    seq.add(Dropout(0.3))# added extra\n",
        "    seq.add(ZeroPadding2D((1, 1)))\n",
        "\n",
        "    seq.add(Conv2D(384, kernel_size=(3, 3), activation='relu', name='conv3_1', strides=1))\n",
        "    seq.add(ZeroPadding2D((1, 1)))\n",
        "\n",
        "    seq.add(Conv2D(256, kernel_size=(3, 3), activation='relu', name='conv3_2', strides=1))    \n",
        "    seq.add(MaxPooling2D((3,3), strides=(2, 2)))\n",
        "    seq.add(Dropout(0.3))# added extra\n",
        "    seq.add(Flatten(name='flatten'))\n",
        "    seq.add(Dense(1024, activation='relu'))\n",
        "    seq.add(Dropout(0.5))\n",
        "\n",
        "    seq.add(Dense(128, activation='relu')) # softmax changed to relu\n",
        "    return seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rrzWNLmX0--G",
        "colab": {}
      },
      "source": [
        "# All the images will be converted to the same size before processing\n",
        "img_h, img_w = 155, 220"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m5Zna9KirCUV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "c2616b1d-2262-4a38-b167-4d343e5ca6ea"
      },
      "source": [
        "input_shape=(img_h, img_w, 1)\n",
        "\n",
        "# network definition\n",
        "base_network = create_base_network_signet(input_shape = input_shape)\n",
        "\n",
        "input_a = Input(shape=(input_shape))\n",
        "input_b = Input(shape=(input_shape))\n",
        "\n",
        "# because we re-use the same instance `base_network`,\n",
        "# the weights of the network\n",
        "# will be shared across the two branches\n",
        "processed_a = base_network(input_a)\n",
        "processed_b = base_network(input_b)\n",
        "\n",
        "# Compute the Euclidean distance between the two vectors in the latent space\n",
        "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
        "\n",
        "model = Model(inputs=[input_a, input_b], outputs=distance)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 155, 220, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 155, 220, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 128)          6460864     input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 1)            0           sequential[1][0]                 \n",
            "                                                                 sequential[2][0]                 \n",
            "==================================================================================================\n",
            "Total params: 6,460,864\n",
            "Trainable params: 6,460,864\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bOs6Ms5q26q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch(lst_folder_img, img_h, img_w, batch_size = 32):\n",
        "    while True:\n",
        "        k = 0\n",
        "        pairs=[np.zeros((batch_size, img_h, img_w, 1)) for i in range(2)]\n",
        "        targets=np.zeros((batch_size,))\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            if i % 2 == 0:\n",
        "                rand_folder = random.sample(lst_folder_img, 1)\n",
        "                lst_img = os.listdir(\"Generated_data/\"+rand_folder[0])\n",
        "                # pairs_img = [ind for ind in random.sample(lst_img, 2)]\n",
        "                pairs_img = random.sample(lst_img, 2)\n",
        "                img0 = cv2.imread(\"Generated_data/\"+rand_folder[0]+\"/\"+pairs_img[0])\n",
        "                img0 = cv2.cvtColor(img0, cv2.COLOR_BGR2GRAY)\n",
        "                img0 = cv2.resize(img0, (img_w,img_h))\n",
        "\n",
        "                img1 = cv2.imread(\"Generated_data/\"+rand_folder[0]+\"/\"+pairs_img[1])\n",
        "                img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "                img1 = cv2.resize(img1, (img_w,img_h))\n",
        "\n",
        "                img0 = np.array(img0, dtype = np.float64)\n",
        "                img1 = np.array(img1, dtype = np.float64)\n",
        "                img0 /= 255\n",
        "                img1 /= 255\n",
        "                img0 = img0[..., np.newaxis]\n",
        "                img1 = img1[..., np.newaxis]\n",
        "\n",
        "                pairs[0][k, :, :, :] = img0\n",
        "                pairs[1][k, :, :, :] = img1\n",
        "\n",
        "                targets[k] = 1\n",
        "                k += 1\n",
        "                \n",
        "            else:\n",
        "                imposite_pair = random.sample(lst_folder_img, 2)\n",
        "                lst_img0 = os.listdir(\"Generated_data/\"+imposite_pair[0])\n",
        "                img0 = cv2.imread(\"Generated_data/\"+imposite_pair[0]+\"/\"+random.sample(lst_img0, 1)[0])\n",
        "                img0 = cv2.cvtColor(img0, cv2.COLOR_BGR2GRAY)\n",
        "                img0 = cv2.resize(img0, (img_w,img_h))\n",
        "\n",
        "                lst_img1 = os.listdir(\"Generated_data/\"+imposite_pair[1])\n",
        "                img1 = cv2.imread(\"Generated_data/\"+imposite_pair[1]+\"/\"+random.sample(lst_img1, 1)[0])\n",
        "                img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "                img1 = cv2.resize(img1, (img_w,img_h))\n",
        "\n",
        "                img0 = np.array(img0, dtype = np.float64)\n",
        "                img1 = np.array(img1, dtype = np.float64)\n",
        "                img0 /= 255\n",
        "                img1 /= 255\n",
        "                img0 = img0[..., np.newaxis]\n",
        "                img1 = img1[..., np.newaxis]\n",
        "\n",
        "                pairs[0][k, :, :, :] = img0\n",
        "                pairs[1][k, :, :, :] = img1\n",
        "\n",
        "                targets[k] = 0\n",
        "                k += 1\n",
        "            if k == batch_size:\n",
        "                yield pairs, targets\n",
        "                k = 0\n",
        "                pairs=[np.zeros((batch_size, img_h, img_w, 1)) for i in range(2)]\n",
        "                targets=np.zeros((batch_size,))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "52H6F3C602YH",
        "colab": {}
      },
      "source": [
        "# compile model using RMSProp Optimizer and Contrastive loss function defined above\n",
        "rms = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08)\n",
        "model.compile(loss=contrastive_loss, optimizer=rms)\n",
        "model.save('siamese1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0RsFWJnKYx5y",
        "colab": {}
      },
      "source": [
        "# Using Keras Callbacks, save the model after every epoch\n",
        "# Reduce the learning rate by a factor of 0.1 if the validation loss does not improve for 5 epochs\n",
        "# Stop the training using early stopping if the validation loss does not improve for 12 epochs\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=12, verbose=1),\n",
        "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.000001, verbose=1),\n",
        "    ModelCheckpoint('./Weights1/signet-bhsig260-{epoch:03d}.h5', verbose=1, save_weights_only=True)\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PZuNH7LaY3vt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "ecbc6a50-2c72-4875-fbf2-965c4f386f04"
      },
      "source": [
        "batch_size = 32\n",
        "model.fit(\n",
        "    generate_batch(lst_train_folder, img_h, img_w, batch_size = 32),\n",
        "    # data_generator(lst_train_folder,batch_size = batch_size),\n",
        "    steps_per_epoch = 50000//batch_size,\n",
        "    epochs=50,\n",
        "#     callbacks = callbacks,\n",
        "    validation_data = generate_batch(lst_val_folder, img_h, img_w, batch_size = 32),\n",
        "    validation_steps = 15000//batch_size,\n",
        "    callbacks = callbacks\n",
        "    \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 1562 steps, validate for 468 steps\n",
            "Epoch 1/50\n",
            "1561/1562 [============================>.] - ETA: 1s - loss: 0.0740\n",
            "Epoch 00001: saving model to ./Weights1/signet-bhsig260-001.h5\n",
            "1562/1562 [==============================] - 2453s 2s/step - loss: 0.0739 - val_loss: 0.0717\n",
            "Epoch 2/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0529\n",
            "Epoch 00002: saving model to ./Weights1/signet-bhsig260-002.h5\n",
            "1562/1562 [==============================] - 1873s 1s/step - loss: 0.0528 - val_loss: 0.0656\n",
            "Epoch 3/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0457\n",
            "Epoch 00003: saving model to ./Weights1/signet-bhsig260-003.h5\n",
            "1562/1562 [==============================] - 1969s 1s/step - loss: 0.0457 - val_loss: 0.0690\n",
            "Epoch 4/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0412\n",
            "Epoch 00004: saving model to ./Weights1/signet-bhsig260-004.h5\n",
            "1562/1562 [==============================] - 1921s 1s/step - loss: 0.0412 - val_loss: 0.0621\n",
            "Epoch 5/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0391\n",
            "Epoch 00005: saving model to ./Weights1/signet-bhsig260-005.h5\n",
            "1562/1562 [==============================] - 1951s 1s/step - loss: 0.0390 - val_loss: 0.0635\n",
            "Epoch 6/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0370\n",
            "Epoch 00006: saving model to ./Weights1/signet-bhsig260-006.h5\n",
            "1562/1562 [==============================] - 1962s 1s/step - loss: 0.0370 - val_loss: 0.0651\n",
            "Epoch 7/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0355\n",
            "Epoch 00007: saving model to ./Weights1/signet-bhsig260-007.h5\n",
            "1562/1562 [==============================] - 1942s 1s/step - loss: 0.0355 - val_loss: 0.0759\n",
            "Epoch 8/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0347\n",
            "Epoch 00008: saving model to ./Weights1/signet-bhsig260-008.h5\n",
            "1562/1562 [==============================] - 1903s 1s/step - loss: 0.0347 - val_loss: 0.0594\n",
            "Epoch 9/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0330\n",
            "Epoch 00009: saving model to ./Weights1/signet-bhsig260-009.h5\n",
            "1562/1562 [==============================] - 1877s 1s/step - loss: 0.0330 - val_loss: 0.0594\n",
            "Epoch 10/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00010: saving model to ./Weights1/signet-bhsig260-010.h5\n",
            "1562/1562 [==============================] - 1900s 1s/step - loss: 0.0310 - val_loss: 0.0650\n",
            "Epoch 11/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0313\n",
            "Epoch 00011: saving model to ./Weights1/signet-bhsig260-011.h5\n",
            "1562/1562 [==============================] - 1918s 1s/step - loss: 0.0313 - val_loss: 0.0683\n",
            "Epoch 12/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0300\n",
            "Epoch 00012: saving model to ./Weights1/signet-bhsig260-012.h5\n",
            "1562/1562 [==============================] - 1910s 1s/step - loss: 0.0300 - val_loss: 0.0652\n",
            "Epoch 13/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0300\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "\n",
            "Epoch 00013: saving model to ./Weights1/signet-bhsig260-013.h5\n",
            "1562/1562 [==============================] - 1914s 1s/step - loss: 0.0301 - val_loss: 0.0611\n",
            "Epoch 14/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0261\n",
            "Epoch 00014: saving model to ./Weights1/signet-bhsig260-014.h5\n",
            "1562/1562 [==============================] - 1902s 1s/step - loss: 0.0261 - val_loss: 0.0638\n",
            "Epoch 15/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0251\n",
            "Epoch 00015: saving model to ./Weights1/signet-bhsig260-015.h5\n",
            "1562/1562 [==============================] - 1929s 1s/step - loss: 0.0251 - val_loss: 0.0634\n",
            "Epoch 16/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0248\n",
            "Epoch 00016: saving model to ./Weights1/signet-bhsig260-016.h5\n",
            "1562/1562 [==============================] - 1912s 1s/step - loss: 0.0248 - val_loss: 0.0630\n",
            "Epoch 17/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0243\n",
            "Epoch 00017: saving model to ./Weights1/signet-bhsig260-017.h5\n",
            "1562/1562 [==============================] - 1864s 1s/step - loss: 0.0243 - val_loss: 0.0657\n",
            "Epoch 18/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0247\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\n",
            "Epoch 00018: saving model to ./Weights1/signet-bhsig260-018.h5\n",
            "1562/1562 [==============================] - 1899s 1s/step - loss: 0.0247 - val_loss: 0.0627\n",
            "Epoch 19/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0233\n",
            "Epoch 00019: saving model to ./Weights1/signet-bhsig260-019.h5\n",
            "1562/1562 [==============================] - 1833s 1s/step - loss: 0.0233 - val_loss: 0.0611\n",
            "Epoch 20/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0237\n",
            "Epoch 00020: saving model to ./Weights1/signet-bhsig260-020.h5\n",
            "1562/1562 [==============================] - 1839s 1s/step - loss: 0.0237 - val_loss: 0.0642\n",
            "Epoch 21/50\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.0233\n",
            "Epoch 00021: saving model to ./Weights1/signet-bhsig260-021.h5\n",
            "1562/1562 [==============================] - 1932s 1s/step - loss: 0.0233 - val_loss: 0.0644\n",
            "Epoch 00021: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1c987c94d88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "adN4vbkIKCPB",
        "colab": {}
      },
      "source": [
        "model.save('siamese2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fZSJYHT38D2h",
        "colab": {}
      },
      "source": [
        "# from tensorflow.keras.models import load_model\n",
        "# model.load_weights('siamese.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zNMy9ykpg-qo",
        "colab": {}
      },
      "source": [
        "def compute_accuracy_roc(predictions, labels):\n",
        "    '''Compute ROC accuracy with a range of thresholds on distances.\n",
        "    '''\n",
        "    dmax = np.max(predictions)\n",
        "    dmin = np.min(predictions)\n",
        "    nsame = np.sum(labels == 1)\n",
        "    ndiff = np.sum(labels == 0)\n",
        "   \n",
        "    step = 0.01\n",
        "    max_acc = 0\n",
        "    best_thresh = -1\n",
        "   \n",
        "    for d in np.arange(dmin, dmax+step, step):\n",
        "        idx1 = predictions.ravel() <= d\n",
        "        idx2 = predictions.ravel() > d\n",
        "       \n",
        "        tpr = float(np.sum(labels[idx1] == 1)) / nsame       \n",
        "        tnr = float(np.sum(labels[idx2] == 0)) / ndiff\n",
        "        acc = 0.5 * (tpr + tnr)       \n",
        "#       print ('ROC', acc, tpr, tnr)\n",
        "       \n",
        "        if (acc > max_acc):\n",
        "            max_acc, best_thresh = acc, d\n",
        "           \n",
        "    return max_acc, best_thresh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eob6p0vTmUl7",
        "colab": {}
      },
      "source": [
        "def generate_batch_test(lst_folder_img, img_h, img_w, batch_size = 32):\n",
        "    while True:\n",
        "        k = 0\n",
        "        pairs=[np.zeros((batch_size, img_h, img_w, 1)) for i in range(2)]\n",
        "        targets=np.zeros((batch_size,))\n",
        "\n",
        "        odd_eve_rand = random.sample(range(10),1)[0]\n",
        "\n",
        "        if odd_eve_rand % 2 == 0:\n",
        "            rand_folder = random.sample(lst_folder_img, 1)\n",
        "            lst_img = os.listdir(\"sample/\"+rand_folder[0])\n",
        "            # pairs_img = [ind for ind in random.sample(lst_img, 2)]\n",
        "            pairs_img = random.sample(lst_img, 2)\n",
        "            img0 = cv2.imread(\"sample/\"+rand_folder[0]+\"/\"+pairs_img[0])\n",
        "            img0 = cv2.cvtColor(img0, cv2.COLOR_BGR2GRAY)\n",
        "            img0 = cv2.resize(img0, (img_w,img_h))\n",
        "\n",
        "            img1 = cv2.imread(\"sample/\"+rand_folder[0]+\"/\"+pairs_img[1])\n",
        "            img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "            img1 = cv2.resize(img1, (img_w,img_h))\n",
        "\n",
        "            img0 = np.array(img0, dtype = np.float64)\n",
        "            img1 = np.array(img1, dtype = np.float64)\n",
        "            img0 /= 255\n",
        "            img1 /= 255\n",
        "            img0 = img0[..., np.newaxis]\n",
        "            img1 = img1[..., np.newaxis]\n",
        "\n",
        "            pairs[0][k, :, :, :] = img0\n",
        "            pairs[1][k, :, :, :] = img1\n",
        "\n",
        "            targets[k] = 1\n",
        "            k += 1\n",
        "            \n",
        "        else:\n",
        "            imposite_pair = random.sample(lst_folder_img, 2)\n",
        "            lst_img0 = os.listdir(\"sample/\"+imposite_pair[0])\n",
        "            img0 = cv2.imread(\"sample/\"+imposite_pair[0]+\"/\"+random.sample(lst_img0, 1)[0])\n",
        "            img0 = cv2.cvtColor(img0, cv2.COLOR_BGR2GRAY)\n",
        "            img0 = cv2.resize(img0, (img_w,img_h))\n",
        "\n",
        "            lst_img1 = os.listdir(\"sample/\"+imposite_pair[1])\n",
        "            img1 = cv2.imread(\"sample/\"+imposite_pair[1]+\"/\"+random.sample(lst_img1, 1)[0])\n",
        "            img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "            img1 = cv2.resize(img1, (img_w,img_h))\n",
        "\n",
        "            img0 = np.array(img0, dtype = np.float64)\n",
        "            img1 = np.array(img1, dtype = np.float64)\n",
        "            img0 /= 255\n",
        "            img1 /= 255\n",
        "            img0 = img0[..., np.newaxis]\n",
        "            img1 = img1[..., np.newaxis]\n",
        "\n",
        "            pairs[0][k, :, :, :] = img0\n",
        "            pairs[1][k, :, :, :] = img1\n",
        "\n",
        "            targets[k] = 0\n",
        "            k += 1\n",
        "        if k == batch_size:\n",
        "            yield pairs, targets\n",
        "            k = 0\n",
        "            pairs=[np.zeros((batch_size, img_h, img_w, 1)) for i in range(2)]\n",
        "            targets=np.zeros((batch_size,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OH2eNs0XKwFO",
        "colab": {}
      },
      "source": [
        "test_gen = generate_batch_test(lst_test_folder, img_h, img_w, batch_size = 1)\n",
        "pred, tr_y = [], []\n",
        "for i in range(200):\n",
        "    (img1, img2), label = next(test_gen)\n",
        "    tr_y.append(label)\n",
        "    pred.append(model.predict([img1, img2])[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "29Ndb1c_UMjq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "078d0674-ed8d-40a1-d70a-adb86380e830"
      },
      "source": [
        "tr_acc, threshold = compute_accuracy_roc(np.array(pred), np.array(tr_y))\n",
        "tr_acc, threshold\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.937092731829574, 0.42)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQNan41Pq27o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}